{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning-RESNET.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOcFHJAxh03iRhbhYyZvfHi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zarah-ml/Car-classification/blob/main/TransferLearning_RESNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icHfYEC-u6cm"
      },
      "source": [
        "# **Car classification using Transfer Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UC5NzKasvbE"
      },
      "source": [
        "!pip3 install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1fZ6JmtvJyL"
      },
      "source": [
        "## Download dataset \n",
        "We are using Stanford car dataset that contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images. The devkit folder includes class labels for training images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9sCL8bCHlPb"
      },
      "source": [
        "!wget http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
        "!wget http://imagenet.stanford.edu/internal/car196/cars_test.tgz\n",
        "!wget https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\n",
        "!tar xzf cars_train.tgz\n",
        "!tar xzf cars_test.tgz\n",
        "!tar xzf car_devkit.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzBYv1Hp68B5"
      },
      "source": [
        "Mount Google drive to save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRFFtz6pvFiY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PAhe5wa4-Yj"
      },
      "source": [
        "## Define utility functions\n",
        "Here we define functions to display training and validation losses and accuracy. We also define CarDataset function to preprocess training images and labels to be used by dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feD5gh0TtZ3X"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy import io \n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "matplotlib.style.use('ggplot')\n",
        "\n",
        "def save_plot(train, valid, plot_name):\n",
        "    # loss plots\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(train, color='orange', label='train_' + plot_name)\n",
        "    plt.plot(valid, color='red', label='validataion_' + plot_name)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(plot_name)\n",
        "    plt.legend()\n",
        "    plt.savefig('./' + plot_name + '.jpg')\n",
        "    plt.show()\n",
        "\n",
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs==labels)/float(labels.size)\n",
        "\n",
        "class carDataset(Dataset):\n",
        "  def __init__(self, image_dir, annotation_file, transform, train = True):\n",
        "    \n",
        "    self.img_dir = image_dir\n",
        "    self.ann_file = annotation_file\n",
        "    self.transform = transform\n",
        "\n",
        "    self.img_list = []\n",
        "    self.trg_list = []\n",
        "\n",
        "    mat_file = io.loadmat(self.ann_file)\n",
        "\n",
        "    for idx, img in enumerate(mat_file['annotations'][0]):\n",
        "              \n",
        "        path = os.path.join(self.img_dir, img[-1][0])\n",
        "        img_data = Image.open(path).convert(\"RGB\")\n",
        "               \n",
        "        if img[-2][0][0] <=196:\n",
        "            self.trg_list.append(img[-2][0][0]-1)\n",
        "            self.img_list.append(img_data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    img = self.img_list[index]\n",
        "    img = self.transform(img)\n",
        "    target = self.trg_list[index]\n",
        "    \n",
        "    return img , target\n",
        "\n",
        "  def __len__(self):\n",
        "   return len(self.img_list)\n",
        "     \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGVieolv5Vaq"
      },
      "source": [
        "## Training and Validation\n",
        "Here we define functions to train and validate the model at each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg0QIuyDuCvX"
      },
      "source": [
        "def train(model, dataloader, dataset, device, optimizer, scheduler, criterion, epoch, path):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    batch_acc = 0\n",
        "    counter = 0\n",
        "    for idx, (images, labels) in tqdm(enumerate(dataloader)):\n",
        "        counter += 1\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        running_loss += loss.item()\n",
        "        optimizer.step()\n",
        "       \n",
        "        labels = labels.data.cpu().numpy()\n",
        "        outputs = outputs.data.cpu().numpy()\n",
        "        batch_acc += accuracy(outputs, labels)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "               torch.save(model.state_dict(), path)\n",
        "\n",
        "    \n",
        "    train_loss = running_loss / counter \n",
        "    train_acc =  100 * (batch_acc / counter)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def validate(model, dataloader, dataset, device, scheduler, criterion):\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_batch_acc = 0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, (images, labels) in tqdm(enumerate(dataloader)):\n",
        "            counter += 1\n",
        "            \n",
        "            images = images.to(device)\n",
        "            labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
        "                        \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item()\n",
        "            labels = labels.data.cpu().numpy()\n",
        "            outputs = outputs.data.cpu().numpy()\n",
        "            val_batch_acc += accuracy(outputs, labels)     \n",
        "            \n",
        "                           \n",
        "    val_loss = val_running_loss / counter\n",
        "    val_acc =  100 * (val_batch_acc / counter)\n",
        "    scheduler.step(val_acc)\n",
        "    return val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br5Lhyd0YwJp"
      },
      "source": [
        "## Load Model\n",
        "Here we create some transforms for our data and load the train/validate data + labels. We load the pretrained Resnet50 model and freeze all layers except the last residual block. We change the output dimensions of the fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjjKZKcfy5X-"
      },
      "source": [
        "def main(learning_rate, batch_size, epochs):\n",
        "  \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    train_transform = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                       transforms.RandomRotation(30),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    \n",
        "    valid_transform = transforms.Compose([transforms.Resize((244,244)),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    data_ann_path = './devkit/cars_train_annos.mat'\n",
        "    data_img_path = './cars_train'\n",
        "    dataset =  carDataset(data_img_path,data_ann_path, train_transform, train= True)\n",
        "\n",
        "    # splitting our data\n",
        "    valid_size  = int(0.1 * len(dataset))\n",
        "    train_size = len(dataset) - valid_size\n",
        "    trainset, validset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "    train_loader = DataLoader( trainset, batch_size=batch_size, shuffle=True )\n",
        "    valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    # path to save the model\n",
        "    model_save_name = 'carclassification.pt'\n",
        "    path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "\n",
        "    # set the learning parameters\n",
        "    hparams = {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "    }\n",
        "\n",
        "    # initialize the model\n",
        "    model = models.resnet34(pretrained=True).to(device)\n",
        "\n",
        "    num_ftrs = model.fc.in_features\n",
        "    print(num_ftrs)\n",
        "\n",
        "    model.fc = nn.Sequential(\n",
        "               nn.Dropout(0.5),\n",
        "               nn.Linear(num_ftrs, 196)).to(device)   \n",
        "    \n",
        "    #print(model.parameters)\n",
        "    #for name, param in model.named_parameters():\n",
        "        #print(name,param.requires_grad)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=hparams['learning_rate'], momentum=0.9)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
        "\n",
        "    # a list to save all the train and validation loss \n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "    train_acc = []\n",
        "    valid_acc = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "        train_epoch_loss, train_epoch_acc = train(model, train_loader, trainset, device, optimizer,  scheduler, criterion, epoch, path)\n",
        "        valid_epoch_loss, valid_epoch_acc = validate(model, valid_loader, validset, device,  scheduler, criterion)\n",
        "\n",
        "        train_loss.append(train_epoch_loss)\n",
        "        valid_loss.append(valid_epoch_loss)\n",
        "        train_acc.append(train_epoch_acc)\n",
        "        valid_acc.append(valid_epoch_acc)\n",
        "\n",
        "        \n",
        "        print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
        "        print(f\"Val Loss: {valid_epoch_loss:.4f}\")\n",
        "        print(f\"Train accuracy: {train_epoch_acc:.4f}\")\n",
        "        print(f\"Val accuracy: {valid_epoch_acc:.4f}\")\n",
        "\n",
        "   \n",
        "    # save the loss plots to disk\n",
        "    save_plot(train_loss, valid_loss, \"loss\")\n",
        "    save_plot(train_acc, valid_acc, \"accuracy\")\n",
        "\n",
        "    print('Training Complete!!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB4GH1hqE1Jn"
      },
      "source": [
        "learning_rate = 0.01\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "main(learning_rate, batch_size, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}